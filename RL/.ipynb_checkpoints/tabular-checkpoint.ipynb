{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce0b7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1aed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maze import Maze\n",
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3f4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "    def __init__(self, game_env: gym.Env):\n",
    "        self.env = game_env\n",
    "        self.q_table = {}\n",
    "        self.pre_state = None\n",
    "        self.alpha = 0.1\n",
    "        self.epsilon = 0.2\n",
    "        self.done = True\n",
    "        self.steps_list = np.zeros(shape=(10,))\n",
    "        self.pos = 0\n",
    "        self.rewards_list = np.zeros(shape=(10,))\n",
    "        self.calculate_count = 0\n",
    "\n",
    "    def get_value(self, state: np.ndarray, action: int):\n",
    "        if len(state.shape) > 1:\n",
    "            raise Exception(\"不支持图像。\")\n",
    "        key = str(state)[1:-1] + str(action)\n",
    "        if key in self.q_table.keys():\n",
    "            return self.q_table[key]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def set_value(self, state: np.ndarray, action: int, value: float):\n",
    "        if len(state.shape) > 1:\n",
    "            raise Exception(\"不支持图像。\")\n",
    "        key = str(state)[1:-1] + str(action)\n",
    "        self.q_table[key] = value\n",
    "\n",
    "    def get_best_action(self, state):\n",
    "        actions = []\n",
    "        values = []\n",
    "        for action in range(self.env.action_space.n):\n",
    "            actions.append(action)\n",
    "            values.append(self.get_value(state, action))\n",
    "        max_value = max(values)\n",
    "        best_actions = []\n",
    "        for i in range(len(values)):\n",
    "            if values[i] == max_value:\n",
    "                best_actions.append(i)\n",
    "        return random.choice(best_actions)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        best_action = self.get_best_action(state)\n",
    "        random_action = random.choice([x for x in range(self.env.action_space.n)])\n",
    "        return np.random.choice([random_action, best_action], p=[self.epsilon, 1 - self.epsilon])\n",
    "\n",
    "    def display(self, step):\n",
    "        print(\"--------------------\")\n",
    "        print(\"num_steps:\", np.average(self.steps_list))\n",
    "        print(\"sum_rewards:\", np.average(self.rewards_list))\n",
    "        print(\"steps:\", step)\n",
    "        print(\"calculate_count:\", self.calculate_count)\n",
    "        print('--------------------')\n",
    "        if np.average(self.steps_list) < 20:\n",
    "            return True\n",
    "\n",
    "    def learn(self, total_steps):\n",
    "        done_count = 0\n",
    "        sum_rewards = 0\n",
    "        step_count = 0\n",
    "        step = 0\n",
    "        for step in range(total_steps):\n",
    "            if self.done:\n",
    "                self.pre_state = self.env.reset()\n",
    "                self.done = False\n",
    "            else:\n",
    "                pass\n",
    "            action = self.get_action(self.pre_state)\n",
    "            step_count += 1\n",
    "            state, reward, done, info = self.env.step(action)\n",
    "            max_next_value = self.get_value(state, self.get_best_action(state))\n",
    "            pre_state_action_value = self.get_value(self.pre_state, action)\n",
    "            value = pre_state_action_value + self.alpha * (max_next_value + reward - pre_state_action_value)\n",
    "            self.calculate_count += 1\n",
    "            self.set_value(self.pre_state, action, value)\n",
    "            self.pre_state = state\n",
    "            if done:\n",
    "                done_count += 1\n",
    "                self.done = done\n",
    "                self.steps_list[self.pos] = step_count\n",
    "                self.rewards_list[self.pos] = sum_rewards\n",
    "                self.pos = (self.pos + 1) % 10\n",
    "                end = False\n",
    "                if done_count % 10 == 0:\n",
    "                    end = self.display(step)\n",
    "                sum_rewards = 0\n",
    "                step_count = 0\n",
    "                if end:\n",
    "                    break\n",
    "        return step, self.calculate_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b7928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniqueQLearning(QLearning):\n",
    "    def __init__(self, game_env):\n",
    "        super(UniqueQLearning, self).__init__(game_env)\n",
    "        self.q_table = np.zeros(shape=(11, 11, 4))\n",
    "\n",
    "    def get_best_action(self, state):\n",
    "        values = self.q_table[state[0], state[1]]\n",
    "        max_value = np.max(values)\n",
    "        indexes = []\n",
    "        for i in range(4):\n",
    "            if values[i] == max_value:\n",
    "                indexes.append(i)\n",
    "        return np.random.choice(indexes)\n",
    "\n",
    "    def set_value(self, state: np.ndarray, action: int, value: float):\n",
    "        self.q_table[state[0], state[1], action] = value\n",
    "\n",
    "    def get_value(self, state: np.ndarray, action: int):\n",
    "        return self.q_table[state[0], state[1], action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a392efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterQLearning(UniqueQLearning):\n",
    "\n",
    "    def learn(self, total_steps):\n",
    "        done_count = 0\n",
    "        sum_rewards = 0\n",
    "        step_count = 0\n",
    "        for step in range(total_steps):\n",
    "            if self.done:\n",
    "                self.pre_state = self.env.reset()\n",
    "                self.done = False\n",
    "            else:\n",
    "                pass\n",
    "            action = self.get_action(self.pre_state)\n",
    "            step_count += 1\n",
    "            state, reward, done, info = self.env.step(action)\n",
    "\n",
    "            # only for maze\n",
    "            if reward == 1:\n",
    "                for action in range(self.env.action_space.n):\n",
    "                    self.set_value(state, action, 100)\n",
    "\n",
    "            max_next_value = self.get_value(state, self.get_best_action(state))\n",
    "            if max_next_value != 0:\n",
    "                pre_state_action_value = self.get_value(self.pre_state, action)\n",
    "                value = pre_state_action_value + self.alpha * (reward + max_next_value - pre_state_action_value)\n",
    "                self.calculate_count += 1\n",
    "                self.set_value(self.pre_state, action, value)\n",
    "\n",
    "            self.pre_state = state\n",
    "            if done:\n",
    "                done_count += 1\n",
    "                self.done = done\n",
    "                self.steps_list[self.pos] = step_count\n",
    "                self.rewards_list[self.pos] = sum_rewards\n",
    "                self.pos = (self.pos + 1) % 10\n",
    "                if done_count % 10 == 0:\n",
    "                    self.display(step)\n",
    "                sum_rewards = 0\n",
    "                step_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17cb5bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithms_compare(*models: QLearning):\n",
    "    data = []\n",
    "    game_env = Maze(use_image=False, is_random=False, x=10, y=10, hit_wall_reward=0, walk_reward=0)\n",
    "    for model in models:\n",
    "        for i in range(100):\n",
    "            model.__init__(game_env)\n",
    "            step, calculate_count = model.learn(1000000)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aece0f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 1999\n",
      "calculate_count: 0\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 3999\n",
      "calculate_count: 0\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 5999\n",
      "calculate_count: 0\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 7999\n",
      "calculate_count: 0\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 197.2\n",
      "sum_rewards: 0.0\n",
      "steps: 9971\n",
      "calculate_count: 1\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 11971\n",
      "calculate_count: 1\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 13971\n",
      "calculate_count: 1\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 15971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 17971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 19971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 21971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 23971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 25971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 27971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 29971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 31971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 33971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 35971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 37971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 39971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 41971\n",
      "calculate_count: 44\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 43971\n",
      "calculate_count: 79\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 190.8\n",
      "sum_rewards: 0.0\n",
      "steps: 45879\n",
      "calculate_count: 169\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 47879\n",
      "calculate_count: 169\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 49879\n",
      "calculate_count: 169\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 200.0\n",
      "sum_rewards: 0.0\n",
      "steps: 51879\n",
      "calculate_count: 287\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 176.0\n",
      "sum_rewards: 0.0\n",
      "steps: 53639\n",
      "calculate_count: 412\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 63.3\n",
      "sum_rewards: 0.0\n",
      "steps: 54272\n",
      "calculate_count: 803\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 64.1\n",
      "sum_rewards: 0.0\n",
      "steps: 54913\n",
      "calculate_count: 1326\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.4\n",
      "sum_rewards: 0.0\n",
      "steps: 55327\n",
      "calculate_count: 1740\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.1\n",
      "sum_rewards: 0.0\n",
      "steps: 55758\n",
      "calculate_count: 2166\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.1\n",
      "sum_rewards: 0.0\n",
      "steps: 56189\n",
      "calculate_count: 2597\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.7\n",
      "sum_rewards: 0.0\n",
      "steps: 56616\n",
      "calculate_count: 3024\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 34.6\n",
      "sum_rewards: 0.0\n",
      "steps: 56962\n",
      "calculate_count: 3370\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.2\n",
      "sum_rewards: 0.0\n",
      "steps: 57374\n",
      "calculate_count: 3771\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.8\n",
      "sum_rewards: 0.0\n",
      "steps: 57812\n",
      "calculate_count: 4209\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 35.3\n",
      "sum_rewards: 0.0\n",
      "steps: 58165\n",
      "calculate_count: 4562\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 56.3\n",
      "sum_rewards: 0.0\n",
      "steps: 58728\n",
      "calculate_count: 5125\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.2\n",
      "sum_rewards: 0.0\n",
      "steps: 59120\n",
      "calculate_count: 5517\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.2\n",
      "sum_rewards: 0.0\n",
      "steps: 59502\n",
      "calculate_count: 5899\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.4\n",
      "sum_rewards: 0.0\n",
      "steps: 59876\n",
      "calculate_count: 6273\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.6\n",
      "sum_rewards: 0.0\n",
      "steps: 60332\n",
      "calculate_count: 6729\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.0\n",
      "sum_rewards: 0.0\n",
      "steps: 60752\n",
      "calculate_count: 7149\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 61.5\n",
      "sum_rewards: 0.0\n",
      "steps: 61367\n",
      "calculate_count: 7764\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 48.9\n",
      "sum_rewards: 0.0\n",
      "steps: 61856\n",
      "calculate_count: 8244\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 48.1\n",
      "sum_rewards: 0.0\n",
      "steps: 62337\n",
      "calculate_count: 8725\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.4\n",
      "sum_rewards: 0.0\n",
      "steps: 62751\n",
      "calculate_count: 9139\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 33.6\n",
      "sum_rewards: 0.0\n",
      "steps: 63087\n",
      "calculate_count: 9472\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.3\n",
      "sum_rewards: 0.0\n",
      "steps: 63580\n",
      "calculate_count: 9965\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.9\n",
      "sum_rewards: 0.0\n",
      "steps: 64009\n",
      "calculate_count: 10394\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.5\n",
      "sum_rewards: 0.0\n",
      "steps: 64394\n",
      "calculate_count: 10772\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.4\n",
      "sum_rewards: 0.0\n",
      "steps: 64888\n",
      "calculate_count: 11266\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.9\n",
      "sum_rewards: 0.0\n",
      "steps: 65277\n",
      "calculate_count: 11655\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.9\n",
      "sum_rewards: 0.0\n",
      "steps: 65686\n",
      "calculate_count: 12064\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.9\n",
      "sum_rewards: 0.0\n",
      "steps: 66135\n",
      "calculate_count: 12513\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.9\n",
      "sum_rewards: 0.0\n",
      "steps: 66544\n",
      "calculate_count: 12922\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 33.8\n",
      "sum_rewards: 0.0\n",
      "steps: 66882\n",
      "calculate_count: 13260\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 52.1\n",
      "sum_rewards: 0.0\n",
      "steps: 67403\n",
      "calculate_count: 13781\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.6\n",
      "sum_rewards: 0.0\n",
      "steps: 67829\n",
      "calculate_count: 14207\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.1\n",
      "sum_rewards: 0.0\n",
      "steps: 68220\n",
      "calculate_count: 14598\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.3\n",
      "sum_rewards: 0.0\n",
      "steps: 68673\n",
      "calculate_count: 15051\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 33.6\n",
      "sum_rewards: 0.0\n",
      "steps: 69009\n",
      "calculate_count: 15387\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.1\n",
      "sum_rewards: 0.0\n",
      "steps: 69460\n",
      "calculate_count: 15838\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 54.9\n",
      "sum_rewards: 0.0\n",
      "steps: 70009\n",
      "calculate_count: 16387\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.4\n",
      "sum_rewards: 0.0\n",
      "steps: 70453\n",
      "calculate_count: 16829\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.4\n",
      "sum_rewards: 0.0\n",
      "steps: 70837\n",
      "calculate_count: 17213\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.1\n",
      "sum_rewards: 0.0\n",
      "steps: 71268\n",
      "calculate_count: 17644\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 51.5\n",
      "sum_rewards: 0.0\n",
      "steps: 71783\n",
      "calculate_count: 18158\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.3\n",
      "sum_rewards: 0.0\n",
      "steps: 72206\n",
      "calculate_count: 18581\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.9\n",
      "sum_rewards: 0.0\n",
      "steps: 72705\n",
      "calculate_count: 19080\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.9\n",
      "sum_rewards: 0.0\n",
      "steps: 73144\n",
      "calculate_count: 19519\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.8\n",
      "sum_rewards: 0.0\n",
      "steps: 73582\n",
      "calculate_count: 19954\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.6\n",
      "sum_rewards: 0.0\n",
      "steps: 73978\n",
      "calculate_count: 20350\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.4\n",
      "sum_rewards: 0.0\n",
      "steps: 74442\n",
      "calculate_count: 20808\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 47.2\n",
      "sum_rewards: 0.0\n",
      "steps: 74914\n",
      "calculate_count: 21280\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.0\n",
      "sum_rewards: 0.0\n",
      "steps: 75374\n",
      "calculate_count: 21730\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "num_steps: 40.6\n",
      "sum_rewards: 0.0\n",
      "steps: 75780\n",
      "calculate_count: 22136\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.7\n",
      "sum_rewards: 0.0\n",
      "steps: 76277\n",
      "calculate_count: 22610\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 36.0\n",
      "sum_rewards: 0.0\n",
      "steps: 76637\n",
      "calculate_count: 22970\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 67.8\n",
      "sum_rewards: 0.0\n",
      "steps: 77315\n",
      "calculate_count: 23643\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.8\n",
      "sum_rewards: 0.0\n",
      "steps: 77763\n",
      "calculate_count: 24091\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 36.1\n",
      "sum_rewards: 0.0\n",
      "steps: 78124\n",
      "calculate_count: 24452\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 47.0\n",
      "sum_rewards: 0.0\n",
      "steps: 78594\n",
      "calculate_count: 24922\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.9\n",
      "sum_rewards: 0.0\n",
      "steps: 79033\n",
      "calculate_count: 25361\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 54.7\n",
      "sum_rewards: 0.0\n",
      "steps: 79580\n",
      "calculate_count: 25908\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.3\n",
      "sum_rewards: 0.0\n",
      "steps: 80023\n",
      "calculate_count: 26351\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.9\n",
      "sum_rewards: 0.0\n",
      "steps: 80442\n",
      "calculate_count: 26770\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.0\n",
      "sum_rewards: 0.0\n",
      "steps: 80902\n",
      "calculate_count: 27230\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.5\n",
      "sum_rewards: 0.0\n",
      "steps: 81327\n",
      "calculate_count: 27655\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.0\n",
      "sum_rewards: 0.0\n",
      "steps: 81697\n",
      "calculate_count: 28025\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.6\n",
      "sum_rewards: 0.0\n",
      "steps: 82133\n",
      "calculate_count: 28461\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 47.4\n",
      "sum_rewards: 0.0\n",
      "steps: 82607\n",
      "calculate_count: 28935\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.6\n",
      "sum_rewards: 0.0\n",
      "steps: 83063\n",
      "calculate_count: 29391\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.8\n",
      "sum_rewards: 0.0\n",
      "steps: 83491\n",
      "calculate_count: 29819\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.4\n",
      "sum_rewards: 0.0\n",
      "steps: 83875\n",
      "calculate_count: 30194\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.7\n",
      "sum_rewards: 0.0\n",
      "steps: 84292\n",
      "calculate_count: 30611\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.3\n",
      "sum_rewards: 0.0\n",
      "steps: 84695\n",
      "calculate_count: 31014\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.9\n",
      "sum_rewards: 0.0\n",
      "steps: 85104\n",
      "calculate_count: 31423\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.9\n",
      "sum_rewards: 0.0\n",
      "steps: 85553\n",
      "calculate_count: 31872\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 48.2\n",
      "sum_rewards: 0.0\n",
      "steps: 86035\n",
      "calculate_count: 32354\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.7\n",
      "sum_rewards: 0.0\n",
      "steps: 86432\n",
      "calculate_count: 32751\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 54.5\n",
      "sum_rewards: 0.0\n",
      "steps: 86977\n",
      "calculate_count: 33296\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.7\n",
      "sum_rewards: 0.0\n",
      "steps: 87354\n",
      "calculate_count: 33673\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 36.9\n",
      "sum_rewards: 0.0\n",
      "steps: 87723\n",
      "calculate_count: 34042\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.2\n",
      "sum_rewards: 0.0\n",
      "steps: 88095\n",
      "calculate_count: 34414\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.5\n",
      "sum_rewards: 0.0\n",
      "steps: 88520\n",
      "calculate_count: 34839\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.6\n",
      "sum_rewards: 0.0\n",
      "steps: 88926\n",
      "calculate_count: 35245\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 48.4\n",
      "sum_rewards: 0.0\n",
      "steps: 89410\n",
      "calculate_count: 35729\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.9\n",
      "sum_rewards: 0.0\n",
      "steps: 89859\n",
      "calculate_count: 36178\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 31.7\n",
      "sum_rewards: 0.0\n",
      "steps: 90176\n",
      "calculate_count: 36495\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 51.4\n",
      "sum_rewards: 0.0\n",
      "steps: 90690\n",
      "calculate_count: 37009\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.4\n",
      "sum_rewards: 0.0\n",
      "steps: 91184\n",
      "calculate_count: 37503\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.2\n",
      "sum_rewards: 0.0\n",
      "steps: 91616\n",
      "calculate_count: 37935\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 36.4\n",
      "sum_rewards: 0.0\n",
      "steps: 91980\n",
      "calculate_count: 38299\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 51.1\n",
      "sum_rewards: 0.0\n",
      "steps: 92491\n",
      "calculate_count: 38810\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.4\n",
      "sum_rewards: 0.0\n",
      "steps: 92955\n",
      "calculate_count: 39274\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.8\n",
      "sum_rewards: 0.0\n",
      "steps: 93393\n",
      "calculate_count: 39712\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.0\n",
      "sum_rewards: 0.0\n",
      "steps: 93773\n",
      "calculate_count: 40092\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.3\n",
      "sum_rewards: 0.0\n",
      "steps: 94146\n",
      "calculate_count: 40465\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.4\n",
      "sum_rewards: 0.0\n",
      "steps: 94650\n",
      "calculate_count: 40969\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 57.3\n",
      "sum_rewards: 0.0\n",
      "steps: 95223\n",
      "calculate_count: 41542\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.6\n",
      "sum_rewards: 0.0\n",
      "steps: 95639\n",
      "calculate_count: 41958\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.7\n",
      "sum_rewards: 0.0\n",
      "steps: 96146\n",
      "calculate_count: 42465\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.7\n",
      "sum_rewards: 0.0\n",
      "steps: 96603\n",
      "calculate_count: 42922\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.4\n",
      "sum_rewards: 0.0\n",
      "steps: 96977\n",
      "calculate_count: 43296\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 36.9\n",
      "sum_rewards: 0.0\n",
      "steps: 97346\n",
      "calculate_count: 43665\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.1\n",
      "sum_rewards: 0.0\n",
      "steps: 97737\n",
      "calculate_count: 44056\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.3\n",
      "sum_rewards: 0.0\n",
      "steps: 98130\n",
      "calculate_count: 44449\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.2\n",
      "sum_rewards: 0.0\n",
      "steps: 98632\n",
      "calculate_count: 44951\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.4\n",
      "sum_rewards: 0.0\n",
      "steps: 99096\n",
      "calculate_count: 45415\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.5\n",
      "sum_rewards: 0.0\n",
      "steps: 99511\n",
      "calculate_count: 45830\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.5\n",
      "sum_rewards: 0.0\n",
      "steps: 99976\n",
      "calculate_count: 46295\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 36.7\n",
      "sum_rewards: 0.0\n",
      "steps: 100343\n",
      "calculate_count: 46662\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.1\n",
      "sum_rewards: 0.0\n",
      "steps: 100714\n",
      "calculate_count: 47033\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.2\n",
      "sum_rewards: 0.0\n",
      "steps: 101206\n",
      "calculate_count: 47525\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 54.5\n",
      "sum_rewards: 0.0\n",
      "steps: 101751\n",
      "calculate_count: 48070\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.3\n",
      "sum_rewards: 0.0\n",
      "steps: 102184\n",
      "calculate_count: 48503\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 48.5\n",
      "sum_rewards: 0.0\n",
      "steps: 102669\n",
      "calculate_count: 48988\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.5\n",
      "sum_rewards: 0.0\n",
      "steps: 103044\n",
      "calculate_count: 49363\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.6\n",
      "sum_rewards: 0.0\n",
      "steps: 103480\n",
      "calculate_count: 49799\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.3\n",
      "sum_rewards: 0.0\n",
      "steps: 103873\n",
      "calculate_count: 50192\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.7\n",
      "sum_rewards: 0.0\n",
      "steps: 104340\n",
      "calculate_count: 50659\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.9\n",
      "sum_rewards: 0.0\n",
      "steps: 104789\n",
      "calculate_count: 51108\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 52.5\n",
      "sum_rewards: 0.0\n",
      "steps: 105314\n",
      "calculate_count: 51633\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 51.4\n",
      "sum_rewards: 0.0\n",
      "steps: 105828\n",
      "calculate_count: 52147\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.0\n",
      "sum_rewards: 0.0\n",
      "steps: 106278\n",
      "calculate_count: 52597\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 52.8\n",
      "sum_rewards: 0.0\n",
      "steps: 106806\n",
      "calculate_count: 53125\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.7\n",
      "sum_rewards: 0.0\n",
      "steps: 107243\n",
      "calculate_count: 53562\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.9\n",
      "sum_rewards: 0.0\n",
      "steps: 107712\n",
      "calculate_count: 54031\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.1\n",
      "sum_rewards: 0.0\n",
      "steps: 108153\n",
      "calculate_count: 54472\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.6\n",
      "sum_rewards: 0.0\n",
      "steps: 108539\n",
      "calculate_count: 54858\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.9\n",
      "sum_rewards: 0.0\n",
      "steps: 108988\n",
      "calculate_count: 55307\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.0\n",
      "sum_rewards: 0.0\n",
      "steps: 109388\n",
      "calculate_count: 55707\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "num_steps: 38.1\n",
      "sum_rewards: 0.0\n",
      "steps: 109769\n",
      "calculate_count: 56088\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.5\n",
      "sum_rewards: 0.0\n",
      "steps: 110194\n",
      "calculate_count: 56513\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.3\n",
      "sum_rewards: 0.0\n",
      "steps: 110697\n",
      "calculate_count: 57014\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.8\n",
      "sum_rewards: 0.0\n",
      "steps: 111125\n",
      "calculate_count: 57442\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.0\n",
      "sum_rewards: 0.0\n",
      "steps: 111525\n",
      "calculate_count: 57842\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 32.9\n",
      "sum_rewards: 0.0\n",
      "steps: 111854\n",
      "calculate_count: 58171\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.2\n",
      "sum_rewards: 0.0\n",
      "steps: 112346\n",
      "calculate_count: 58663\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 54.8\n",
      "sum_rewards: 0.0\n",
      "steps: 112894\n",
      "calculate_count: 59211\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 53.6\n",
      "sum_rewards: 0.0\n",
      "steps: 113430\n",
      "calculate_count: 59747\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.6\n",
      "sum_rewards: 0.0\n",
      "steps: 113826\n",
      "calculate_count: 60143\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.0\n",
      "sum_rewards: 0.0\n",
      "steps: 114316\n",
      "calculate_count: 60633\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.4\n",
      "sum_rewards: 0.0\n",
      "steps: 114770\n",
      "calculate_count: 61087\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 34.7\n",
      "sum_rewards: 0.0\n",
      "steps: 115117\n",
      "calculate_count: 61434\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.5\n",
      "sum_rewards: 0.0\n",
      "steps: 115622\n",
      "calculate_count: 61939\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 53.0\n",
      "sum_rewards: 0.0\n",
      "steps: 116152\n",
      "calculate_count: 62469\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.2\n",
      "sum_rewards: 0.0\n",
      "steps: 116614\n",
      "calculate_count: 62931\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 55.5\n",
      "sum_rewards: 0.0\n",
      "steps: 117169\n",
      "calculate_count: 63486\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.0\n",
      "sum_rewards: 0.0\n",
      "steps: 117589\n",
      "calculate_count: 63906\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 35.6\n",
      "sum_rewards: 0.0\n",
      "steps: 117945\n",
      "calculate_count: 64262\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.8\n",
      "sum_rewards: 0.0\n",
      "steps: 118373\n",
      "calculate_count: 64690\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.4\n",
      "sum_rewards: 0.0\n",
      "steps: 118827\n",
      "calculate_count: 65144\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.4\n",
      "sum_rewards: 0.0\n",
      "steps: 119201\n",
      "calculate_count: 65518\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 61.1\n",
      "sum_rewards: 0.0\n",
      "steps: 119812\n",
      "calculate_count: 66129\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 35.0\n",
      "sum_rewards: 0.0\n",
      "steps: 120162\n",
      "calculate_count: 66479\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.8\n",
      "sum_rewards: 0.0\n",
      "steps: 120620\n",
      "calculate_count: 66937\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.9\n",
      "sum_rewards: 0.0\n",
      "steps: 121049\n",
      "calculate_count: 67366\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 55.6\n",
      "sum_rewards: 0.0\n",
      "steps: 121605\n",
      "calculate_count: 67922\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 47.3\n",
      "sum_rewards: 0.0\n",
      "steps: 122078\n",
      "calculate_count: 68395\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.8\n",
      "sum_rewards: 0.0\n",
      "steps: 122496\n",
      "calculate_count: 68813\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.9\n",
      "sum_rewards: 0.0\n",
      "steps: 122935\n",
      "calculate_count: 69252\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 52.9\n",
      "sum_rewards: 0.0\n",
      "steps: 123464\n",
      "calculate_count: 69781\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.1\n",
      "sum_rewards: 0.0\n",
      "steps: 123845\n",
      "calculate_count: 70162\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 51.6\n",
      "sum_rewards: 0.0\n",
      "steps: 124361\n",
      "calculate_count: 70678\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 36.8\n",
      "sum_rewards: 0.0\n",
      "steps: 124729\n",
      "calculate_count: 71046\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.0\n",
      "sum_rewards: 0.0\n",
      "steps: 125229\n",
      "calculate_count: 71546\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.8\n",
      "sum_rewards: 0.0\n",
      "steps: 125677\n",
      "calculate_count: 71994\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 55.2\n",
      "sum_rewards: 0.0\n",
      "steps: 126229\n",
      "calculate_count: 72546\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.5\n",
      "sum_rewards: 0.0\n",
      "steps: 126654\n",
      "calculate_count: 72971\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 55.1\n",
      "sum_rewards: 0.0\n",
      "steps: 127205\n",
      "calculate_count: 73522\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 47.4\n",
      "sum_rewards: 0.0\n",
      "steps: 127679\n",
      "calculate_count: 73996\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 47.7\n",
      "sum_rewards: 0.0\n",
      "steps: 128156\n",
      "calculate_count: 74473\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 51.9\n",
      "sum_rewards: 0.0\n",
      "steps: 128675\n",
      "calculate_count: 74992\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 52.0\n",
      "sum_rewards: 0.0\n",
      "steps: 129195\n",
      "calculate_count: 75512\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 52.2\n",
      "sum_rewards: 0.0\n",
      "steps: 129717\n",
      "calculate_count: 76034\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 45.3\n",
      "sum_rewards: 0.0\n",
      "steps: 130170\n",
      "calculate_count: 76487\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.3\n",
      "sum_rewards: 0.0\n",
      "steps: 130603\n",
      "calculate_count: 76920\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.6\n",
      "sum_rewards: 0.0\n",
      "steps: 130989\n",
      "calculate_count: 77306\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 54.1\n",
      "sum_rewards: 0.0\n",
      "steps: 131530\n",
      "calculate_count: 77847\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 46.2\n",
      "sum_rewards: 0.0\n",
      "steps: 131992\n",
      "calculate_count: 78309\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.6\n",
      "sum_rewards: 0.0\n",
      "steps: 132408\n",
      "calculate_count: 78725\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.1\n",
      "sum_rewards: 0.0\n",
      "steps: 132909\n",
      "calculate_count: 79226\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.0\n",
      "sum_rewards: 0.0\n",
      "steps: 133279\n",
      "calculate_count: 79596\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 53.0\n",
      "sum_rewards: 0.0\n",
      "steps: 133809\n",
      "calculate_count: 80126\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.1\n",
      "sum_rewards: 0.0\n",
      "steps: 134310\n",
      "calculate_count: 80627\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.9\n",
      "sum_rewards: 0.0\n",
      "steps: 134719\n",
      "calculate_count: 81036\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 50.9\n",
      "sum_rewards: 0.0\n",
      "steps: 135228\n",
      "calculate_count: 81545\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.9\n",
      "sum_rewards: 0.0\n",
      "steps: 135607\n",
      "calculate_count: 81924\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 31.3\n",
      "sum_rewards: 0.0\n",
      "steps: 135920\n",
      "calculate_count: 82237\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 60.0\n",
      "sum_rewards: 0.0\n",
      "steps: 136520\n",
      "calculate_count: 82837\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 39.2\n",
      "sum_rewards: 0.0\n",
      "steps: 136912\n",
      "calculate_count: 83229\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.6\n",
      "sum_rewards: 0.0\n",
      "steps: 137288\n",
      "calculate_count: 83605\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 40.9\n",
      "sum_rewards: 0.0\n",
      "steps: 137697\n",
      "calculate_count: 84014\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.3\n",
      "sum_rewards: 0.0\n",
      "steps: 138190\n",
      "calculate_count: 84507\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.0\n",
      "sum_rewards: 0.0\n",
      "steps: 138680\n",
      "calculate_count: 84997\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 58.8\n",
      "sum_rewards: 0.0\n",
      "steps: 139268\n",
      "calculate_count: 85585\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.4\n",
      "sum_rewards: 0.0\n",
      "steps: 139652\n",
      "calculate_count: 85969\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 41.5\n",
      "sum_rewards: 0.0\n",
      "steps: 140067\n",
      "calculate_count: 86384\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 47.3\n",
      "sum_rewards: 0.0\n",
      "steps: 140540\n",
      "calculate_count: 86857\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 61.7\n",
      "sum_rewards: 0.0\n",
      "steps: 141157\n",
      "calculate_count: 87474\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 57.2\n",
      "sum_rewards: 0.0\n",
      "steps: 141729\n",
      "calculate_count: 88046\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 38.7\n",
      "sum_rewards: 0.0\n",
      "steps: 142116\n",
      "calculate_count: 88433\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 57.5\n",
      "sum_rewards: 0.0\n",
      "steps: 142691\n",
      "calculate_count: 89008\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 49.3\n",
      "sum_rewards: 0.0\n",
      "steps: 143184\n",
      "calculate_count: 89501\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 42.1\n",
      "sum_rewards: 0.0\n",
      "steps: 143605\n",
      "calculate_count: 89922\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 33.1\n",
      "sum_rewards: 0.0\n",
      "steps: 143936\n",
      "calculate_count: 90253\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 56.7\n",
      "sum_rewards: 0.0\n",
      "steps: 144503\n",
      "calculate_count: 90820\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "num_steps: 38.5\n",
      "sum_rewards: 0.0\n",
      "steps: 144888\n",
      "calculate_count: 91205\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.2\n",
      "sum_rewards: 0.0\n",
      "steps: 145320\n",
      "calculate_count: 91637\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 52.6\n",
      "sum_rewards: 0.0\n",
      "steps: 145846\n",
      "calculate_count: 92163\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 44.0\n",
      "sum_rewards: 0.0\n",
      "steps: 146286\n",
      "calculate_count: 92603\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 37.9\n",
      "sum_rewards: 0.0\n",
      "steps: 146665\n",
      "calculate_count: 92982\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 43.9\n",
      "sum_rewards: 0.0\n",
      "steps: 147104\n",
      "calculate_count: 93421\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 47.3\n",
      "sum_rewards: 0.0\n",
      "steps: 147577\n",
      "calculate_count: 93894\n",
      "--------------------\n",
      "--------------------\n",
      "num_steps: 36.1\n",
      "sum_rewards: 0.0\n",
      "steps: 147938\n",
      "calculate_count: 94255\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3992\\10227535.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_random\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhit_wall_reward\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwalk_reward\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mq_learning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBetterQLearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mq_learning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3992\\3744768316.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_steps)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mstep_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3992\\3896605731.py\u001b[0m in \u001b[0;36mget_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mbest_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mrandom_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_action\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = Maze(use_image=False, is_random=False, x=10, y=10, hit_wall_reward=0, walk_reward=0)\n",
    "q_learning = BetterQLearning(env)\n",
    "q_learning.learn(1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
